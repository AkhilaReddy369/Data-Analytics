{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ntN6raDg2h"
      },
      "source": [
        "**Load needed libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6ihhAkZDg2h"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd    # Importing the pandas library, which is used for data manipulation and analysis, particularly with DataFrames.\n",
        "import statsmodels.api as sm    # Importing statsmodels library for statistical modeling and hypothesis testing.\n",
        "import sklearn as sk    # Importing scikit-learn (sklearn), a popular machine learning library for data preprocessing, model building, and evaluation.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor    # Importing a method to calculate Variance Inflation Factor (VIF) to check for multicollinearity in features.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score    # Importing methods for splitting data into training/testing sets and performing cross-validation.\n",
        "from sklearn.linear_model import LinearRegression    # Importing LinearRegression class to create a linear regression model.\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error    # Importing methods to evaluate model performance using mean squared error and mean absolute error.\n",
        "from sklearn.feature_selection import SequentialFeatureSelector    # Importing SequentialFeatureSelector for feature selection using a greedy approach.\n",
        "from sklearn.pipeline import make_pipeline    # Importing make_pipeline to chain multiple steps (preprocessing, modeling) into one pipeline.\n",
        "from sklearn.linear_model import Ridge    # Importing Ridge regression, a type of linear regression that applies L2 regularization.\n",
        "from sklearn.preprocessing import StandardScaler    # Importing StandardScaler to standardize features by removing the mean and scaling to unit variance.\n",
        "from sklearn.linear_model import Lasso    # Importing Lasso regression, a type of linear regression that applies L1 regularization to perform feature selection.\n",
        "from sklearn.linear_model import ElasticNet    # Importing ElasticNet regression, a combination of Lasso and Ridge regression that applies both L1 and L2 regularization.\n",
        "import numpy as np    # Importing numpy library for numerical operations, especially with arrays and matrices.\n",
        "import matplotlib.pyplot as plt    # Importing matplotlib's pyplot module for creating visualizations like plots and graphs.\n",
        "import seaborn as sns    # Importing seaborn, a statistical data visualization library built on top of matplotlib for creating more attractive and informative plots.\n",
        "from statsmodels.stats.stattools import durbin_watson    # Importing the Durbin-Watson statistic function to check for autocorrelation in residuals of a regression model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxDqMI9wDg2i"
      },
      "source": [
        "**Load the data from a csv file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_8E3ybnDg2i"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('college_admissions_2022.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYv2p8leDg2i"
      },
      "source": [
        "**Print Info**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey-TO7mIDg2i"
      },
      "outputs": [],
      "source": [
        "print(df.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_V35CMDg2j"
      },
      "source": [
        "**Print Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZEk5ghjDg2j"
      },
      "outputs": [],
      "source": [
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpPbk8fQDg2j"
      },
      "source": [
        "**Drop the missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VqN17l9Dg2j"
      },
      "outputs": [],
      "source": [
        "# Drop missing values\n",
        "df_cleaned = df.dropna()\n",
        "\n",
        "# Report the size of the remaining dataset\n",
        "remaining_size = df_cleaned.shape\n",
        "print(df_cleaned.info())\n",
        "print(f\"Size of the remaining dataset (rows, columns): {remaining_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "display(df_cleaned)"
      ],
      "metadata": {
        "id": "dwHwfuZEj9eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6bLfscPDg2j"
      },
      "source": [
        "**Remove the variables, 'UNITID', 'INSTNM', 'Appl'  from the dataset. And split the data set into a training set (60%) and a test set (40%) and use random_state=101.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6GACrM2Dg2k"
      },
      "outputs": [],
      "source": [
        "# Remove the specified variables\n",
        "df_cleaned_columns = df_cleaned.drop(columns=['UNITID', 'INSTNM', 'Appl'])\n",
        "print(df_cleaned_columns.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70BLI9cUDg2k"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "\n",
        "print(f\"Training set size (rows, columns): {X_train.shape}\")\n",
        "print(f\"Test set size (rows, columns): {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q138T7nUDg2k"
      },
      "source": [
        "**Fit a linear model using least squares on the training set with all other remaining variables. Report the coefficients, and the test errors, ME, RMSE, MAE, MPE, and MAPE of the validation part.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRBWGXJgDg2k"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "#y = np.log(df_cleaned_columns['Ug_enter'])\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Add a constant to the model (intercept term)\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Fit a linear model using least squares on the training set\n",
        "linear_model = sm.OLS(y_train, X_train_const).fit()\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = linear_model.predict(X_test_const)\n",
        "\n",
        "# Calculate validation errors\n",
        "ME = np.mean(y_pred - y_test)\n",
        "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "MPE = np.mean((y_pred - y_test) / y_test) * 100\n",
        "MAPE = np.mean(np.abs((y_pred - y_test) / y_test)) * 100\n",
        "\n",
        "# Coefficients\n",
        "coefficients = linear_model.params\n",
        "p_values = linear_model.pvalues\n",
        "r_squared = linear_model.rsquared\n",
        "adj_r_squared = linear_model.rsquared_adj\n",
        "f_statistic = linear_model.fvalue\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = linear_model.aic\n",
        "bic = linear_model.bic\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': X_train_const.columns,\n",
        "    'Coefficient': coefficients.values,\n",
        "    'P-Value': p_values.values,\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print()\n",
        "print(\"Model Error Metrics:\")\n",
        "print(\"Mean Error (ME):\", ME)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE)\n",
        "print()\n",
        "print(\"Model Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "linear_ME = ME\n",
        "liner_RMSE = RMSE\n",
        "linear_MAE = MAE\n",
        "linear_MPE = MPE\n",
        "linear_MAPE = MAPE\n",
        "linear_r_squared = r_squared\n",
        "linear_adjusted_r_squared = adj_r_squared\n",
        "linear_f_statistic = f_statistic\n",
        "linear_aic = aic\n",
        "linear_bic = bic\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Linear Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOH5Dn_lDg2k"
      },
      "source": [
        "**Perform backward elimination on the dataset and fit a linear regression model. Report the test error obtained. Which variables were retained in the final model? Additionally, provide the validation errors, including Mean Error (ME), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Percentage Error (MPE), and Mean Absolute Percentage Error (MAPE).**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backward regression (or backward elimination) is a stepwise feature selection technique used in linear regression to build an optimal model by removing the least significant predictors one at a time. It starts with all available independent variables in the model. The algorithm then evaluates the statistical significance of each predictor, typically using p-values from t-tests. If the p-value of the least significant variable exceeds a predefined threshold (e.g., 0.05), that variable is removed from the model. This process is repeated iteratively until only statistically significant predictors remain in the model, ensuring a simpler, more interpretable model with reduced overfitting.\n",
        "\n",
        "Multicollinearity occurs in a regression model when two or more independent variables (predictors) are highly correlated with each other. This means that one predictor can be linearly predicted from the others with a high degree of accuracy, leading to redundant information in the model.\n",
        "\n",
        "**Multicollinearity can cause problems in regression analysis, such as:**\n",
        "\n",
        "Unstable Coefficients: It makes the coefficients of the predictors sensitive to small changes in the data, leading to large variances and unreliable estimates.\n",
        "\n",
        "Interpretation Issues: It becomes difficult to assess the individual effect of each predictor because the variables overlap in the information they provide.\n",
        "\n",
        "Increased Standard Errors: This can lead to statistically insignificant p-values even for predictors that are important.\n",
        "\n",
        "Although multicollinearity doesn't affect the model's overall predictive power, it complicates interpretation and can lead to less precise models. Techniques like Ridge Regression or Variance Inflation Factor (VIF) are often used to detect and address multicollinearity."
      ],
      "metadata": {
        "id": "b2YvqvhezRT2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jmXiZZrDg2k"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "#y = np.log(df_cleaned_columns['Ug_enter'])\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Add a constant to the model (intercept term)\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Perform backward elimination\n",
        "model = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = model.pvalues\n",
        "\n",
        "dropped_variables = []\n",
        "\n",
        "# Iteratively remove variables with the highest p-value greater than 0.05\n",
        "while max(p_values) > 0.05:\n",
        "    dropped_var = p_values.idxmax()\n",
        "    dropped_variables.append(dropped_var)\n",
        "    X_train_const = X_train_const.drop(columns=[dropped_var])\n",
        "    X_test_const = X_test_const.drop(columns=[dropped_var])\n",
        "    model = sm.OLS(y_train, X_train_const).fit()\n",
        "    p_values = model.pvalues\n",
        "\n",
        "# Final model\n",
        "final_model = model\n",
        "y_pred = final_model.predict(X_test_const)\n",
        "\n",
        "# Calculate validation errors for backward elimination model\n",
        "ME = np.mean(y_pred - y_test)\n",
        "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "MPE = np.mean((y_pred - y_test) / y_test) * 100\n",
        "MAPE = np.mean(np.abs((y_pred - y_test) / y_test)) * 100\n",
        "\n",
        "# Coefficients\n",
        "coefficients = final_model.params\n",
        "p_values = final_model.pvalues\n",
        "r_squared = final_model.rsquared\n",
        "adj_r_squared = final_model.rsquared_adj\n",
        "f_statistic = final_model.fvalue\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = final_model.aic\n",
        "bic = final_model.bic\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': X_train_const.columns,\n",
        "    'Coefficient': coefficients.values,\n",
        "    'P-Value': p_values.values,\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print()\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print()\n",
        "print(\"Model Error Statistics:\")\n",
        "print(\"Mean Error (ME):\", ME)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE)\n",
        "print()\n",
        "print(\"Model Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "backward_ME = ME\n",
        "backward_RMSE = RMSE\n",
        "backward_MAE = MAE\n",
        "backward_MPE = MPE\n",
        "backward_MAPE = MAPE\n",
        "backward_r_squared = r_squared\n",
        "backward_adjusted_r_squared = adj_r_squared\n",
        "backward_f_statistic = f_statistic\n",
        "backward_aic = aic\n",
        "backward_bic = bic\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Backward Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hT6Lv7ODg2k"
      },
      "source": [
        "**Fit a forward selection and report the test error obtained. Which variables did you end up with? Which variables did you end up with? What are the validation errors (ME, RMSE, MAE, MPE, and MAPE )**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Forward regression (or forward selection) is a feature selection technique where the model starts with no predictors and adds them one by one based on their statistical significance. At each step, the predictor that improves the model the most (typically by minimizing the error or based on a p-value threshold) is added. This process continues until adding more predictors no longer significantly improves the model.\n",
        "\n",
        "The key difference between forward regression and stepwise regression is that in stepwise regression, after each step (either adding or removing a predictor), the model also checks whether previously included predictors should be removed based on their significance. Stepwise regression is more flexible because it combines elements of both forward and backward selection, whereas forward regression only adds predictors without removing any previously added ones."
      ],
      "metadata": {
        "id": "fZADcbGm2G2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhK1j3BuDg2l"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Perform forward selection\n",
        "linear_model = LinearRegression()\n",
        "sfs = SequentialFeatureSelector(linear_model, direction='forward', scoring='neg_mean_squared_error', cv=5)\n",
        "sfs.fit(X_train, y_train)\n",
        "\n",
        "# Selected features\n",
        "selected_features = sfs.get_support(indices=True)\n",
        "X_train_fs = X_train.iloc[:, selected_features]\n",
        "X_test_fs = X_test.iloc[:, selected_features]\n",
        "\n",
        "# Fit the model using selected features\n",
        "linear_model.fit(X_train_fs, y_train)\n",
        "y_pred_fs = linear_model.predict(X_test_fs)\n",
        "\n",
        "# Calculate validation errors for forward selection model\n",
        "ME_fs = np.mean(y_pred_fs - y_test)\n",
        "RMSE_fs = np.sqrt(mean_squared_error(y_test, y_pred_fs))\n",
        "MAE_fs = mean_absolute_error(y_test, y_pred_fs)\n",
        "MPE_fs = np.mean((y_pred_fs - y_test) / y_test) * 100\n",
        "MAPE_fs = np.mean(np.abs((y_pred_fs - y_test) / y_test)) * 100\n",
        "\n",
        "# Retained and dropped variables\n",
        "initial_variables = X_train.columns.tolist()\n",
        "retained_variables = X_train.columns[selected_features].tolist()\n",
        "dropped_variables = [var for var in initial_variables if var not in retained_variables]\n",
        "\n",
        "# Calculate VIF for each feature in the retained variables\n",
        "X_train_const = sm.add_constant(X_train_fs)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Fit a linear model using statsmodels to get p-values, R-squared, adjusted R-squared, F-statistic, AIC, and BIC\n",
        "linear_model_sm = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = linear_model_sm.pvalues\n",
        "r_squared = linear_model_sm.rsquared\n",
        "adj_r_squared = linear_model_sm.rsquared_adj\n",
        "f_statistic = linear_model_sm.fvalue\n",
        "aic = linear_model_sm.aic\n",
        "bic = linear_model_sm.bic\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_full = [linear_model.intercept_] + linear_model.coef_.tolist()\n",
        "p_values_full = [None] + p_values.tolist()  # Add None for the intercept\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': ['Intercept'] + retained_variables,\n",
        "    'Coefficient': coefficients_full[:len(retained_variables) + 1],\n",
        "    'P-Value': p_values_full[:len(retained_variables) + 1],\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Adjust the lengths of the initial, retained, and dropped variables lists\n",
        "max_length = max(len(initial_variables), len(retained_variables), len(dropped_variables))\n",
        "initial_variables += [None] * (max_length - len(initial_variables))\n",
        "retained_variables += [None] * (max_length - len(retained_variables))\n",
        "dropped_variables += [None] * (max_length - len(dropped_variables))\n",
        "\n",
        "# Create a DataFrame to show the initial, retained, and dropped variables\n",
        "variables_df = pd.DataFrame({\n",
        "    \"Initial Variables\": initial_variables,\n",
        "    \"Retained Variables\": retained_variables,\n",
        "    \"Dropped Variables\": dropped_variables\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print(\"\\nValidation Errors:\")\n",
        "print(\"Mean Error (ME):\", ME_fs)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE_fs)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE_fs)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE_fs)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE_fs)\n",
        "print(\"\\nModel Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "forward_ME = ME\n",
        "forward_RMSE = RMSE\n",
        "forward_MAE = MAE\n",
        "forward_MPE = MPE\n",
        "forward_MAPE = MAPE\n",
        "forward_r_squared = r_squared\n",
        "forward_adjusted_r_squared = adj_r_squared\n",
        "forward_f_statistic = f_statistic\n",
        "forward_aic = aic\n",
        "forward_bic = bic\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred_fs\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_fs, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_fs, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Forward Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh2LxcZCDg2l"
      },
      "source": [
        "**Run a Ridge regression with Standard Scaler, and alpha=0.5 and report the validation errors (ME, RMSE, MAE, MPE, and MAPE ).**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ridge regression is a type of linear regression that includes a penalty term to reduce model complexity and prevent overfitting. It modifies the standard linear regression by adding a regularization term to the loss function, which is the L2 penalty (the square of the magnitude of coefficients). This penalty term discourages large coefficients, effectively shrinking them towards zero. By doing so, ridge regression balances between fitting the data well and maintaining smaller, more generalized coefficients, making it especially useful when there is multicollinearity or when the dataset has many features\n",
        "\n"
      ],
      "metadata": {
        "id": "hCGJItxT39ve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCUZVKZADg2l"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Perform Ridge regression with Standard Scaler and alpha=0.5\n",
        "ridge_model = make_pipeline(StandardScaler(), Ridge(alpha=0.5))\n",
        "ridge_model.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "\n",
        "# Calculate cross-validation scores\n",
        "cv_scores = cross_val_score(ridge_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Calculate validation errors for Ridge regression model\n",
        "ME_ridge = np.mean(y_pred_ridge - y_test)\n",
        "RMSE_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "MAE_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "MPE_ridge = np.mean((y_pred_ridge - y_test) / y_test) * 100\n",
        "MAPE_ridge = np.mean(np.abs((y_pred_ridge - y_test) / y_test)) * 100\n",
        "\n",
        "# Get coefficients and corresponding variable names\n",
        "coefficients = ridge_model.named_steps['ridge'].coef_\n",
        "initial_variables = X_train.columns.tolist()\n",
        "\n",
        "# Set a threshold to consider coefficients as dropped\n",
        "threshold = 1e-5\n",
        "retained_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) > threshold]\n",
        "dropped_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) <= threshold]\n",
        "\n",
        "# Calculate VIF for each feature in the retained variables\n",
        "X_train_retained = X_train[retained_variables]\n",
        "X_train_const = sm.add_constant(X_train_retained)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Fit a linear model using statsmodels to get p-values, AIC, and BIC\n",
        "linear_model_sm = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = linear_model_sm.pvalues\n",
        "r_squared = linear_model_sm.rsquared\n",
        "adj_r_squared = linear_model_sm.rsquared_adj\n",
        "f_statistic = linear_model_sm.fvalue\n",
        "aic = linear_model_sm.aic\n",
        "bic = linear_model_sm.bic\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_full = [ridge_model.named_steps['ridge'].intercept_] + coefficients.tolist()\n",
        "p_values_full = [None] + p_values.tolist()  # Add None for the intercept\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': ['Intercept'] + retained_variables,\n",
        "    'Coefficient': coefficients_full[:len(retained_variables) + 1],\n",
        "    'P-Value': p_values_full[:len(retained_variables) + 1],\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print(\"\\nCross-Validation MSE:\", cv_mse)\n",
        "print(\"\\nValidation Errors:\")\n",
        "print(\"Mean Error (ME):\", ME_ridge)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE_ridge)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE_ridge)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE_ridge)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE_ridge)\n",
        "print(\"\\nModel Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "ridge_ME = ME_ridge\n",
        "ridge_RMSE = RMSE_ridge\n",
        "ridge_MAE = MAE_ridge\n",
        "ridge_MPE = MPE_ridge\n",
        "ridge_MAPE = MAPE_ridge\n",
        "ridge_r_squared = r_squared\n",
        "ridge_adjusted_r_squared = adj_r_squared\n",
        "ridge_f_statistic = f_statistic\n",
        "ridge_aic = aic\n",
        "ridge_bic = bic\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred_ridge\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_ridge, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Regularization Path\n",
        "alphas = np.logspace(-6, 6, 200)\n",
        "coefs = []\n",
        "for a in alphas:\n",
        "    ridge = Ridge(alpha=a)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    coefs.append(ridge.coef_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alphas, coefs)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficients')\n",
        "plt.title('Ridge Regression Regularization Path')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_ridge, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Ridge Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3KelVJ-Dg2l"
      },
      "source": [
        "**Run a Lasso regression with Standard Scaler, and alpha=0.5 and report the validation errors (ME, RMSE, MAE, MPE, and MAPE ).**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analyzing a regularization path in the context of regression models (such as Lasso, Ridge, or Elastic Net regression), the convergence of coefficients toward specific values (like zero or a large value like 10,000) provides important insights into how regularization is affecting the model. Here’s a detailed explanation:\n",
        "\n",
        "What is a Regularization Path?\n",
        "\n",
        "\t•\tThe regularization path shows how the coefficients of the regression model change as the regularization strength (or penalty term) is varied.\n",
        "\t•\tIn regularization, the goal is to control overfitting by shrinking the magnitude of the coefficients.\n",
        "\t•\tAs the regularization strength (controlled by a parameter like alpha or lambda) increases, coefficients are often shrunk towards zero (especially in Lasso or Elastic Net).\n",
        "\n",
        "Convergence to Zero:\n",
        "\n",
        "\t•\tConvergence to zero means that as the regularization parameter increases, the coefficients of the model are gradually shrinking to zero.\n",
        "\t•\tThis is typical behavior in Lasso regression (L1 regularization) and Elastic Net, where some coefficients can be driven exactly to zero.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "\t1.\tSmaller or Less Important Features:\n",
        "\t•\tFeatures with coefficients that converge to zero are likely less important for predicting the target variable.\n",
        "\t•\tIn Lasso, regularization acts as a form of feature selection, setting some coefficients to zero, effectively removing those features from the model.\n",
        "\t2.\tHighly Regularized Model:\n",
        "\t•\tWhen most or all coefficients converge to zero, the model becomes highly regularized and might underfit the data because it is not using enough information from the features.\n",
        "\t3.\tSimplicity of the Model:\n",
        "\t•\tA model with coefficients converging to zero results in a simpler model with fewer features, which may generalize better (especially in the presence of noise or irrelevant features).\n",
        "\n",
        "Convergence to a Large Value (e.g., 10,000):\n",
        "\n",
        "\t•\tIf coefficients converge to large values as the regularization path progresses, it indicates that the model is placing significant importance on certain features.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "\t1.\tKey Features:\n",
        "\t•\tCoefficients that remain large (or grow) despite regularization are likely key predictors of the target variable.\n",
        "\t•\tThese features have a strong relationship with the target, and the model retains their influence even with stronger regularization.\n",
        "\t2.\tModel with Lower Regularization:\n",
        "\t•\tWhen coefficients remain large or don’t shrink much, the regularization is weaker, meaning the model is allowed to fit more complex relationships in the data.\n",
        "\t3.\tPotential Overfitting:\n",
        "\t•\tIf regularization strength is too low, coefficients can become large and may lead to overfitting. The model may become too sensitive to the training data, capturing noise rather than general patterns.\n",
        "\n",
        "Visualizing the Regularization Path:\n",
        "\n",
        "\t•\tThe regularization path plot often shows multiple lines, where each line represents the path of a feature’s coefficient as regularization increases.\n",
        "\t•\tOn the x-axis, the plot might show the value of the regularization parameter (like lambda), and on the y-axis, it shows the coefficient values.\n",
        "\t•\tAt low values of regularization (small lambda), coefficients tend to have larger magnitudes.\n",
        "\t•\tAt high values of regularization (large lambda), coefficients may converge to zero.\n",
        "\n",
        "Convergence at Zero vs 10,000:\n",
        "\n",
        "\t•\tConvergence at Zero: Indicates the feature’s effect is being reduced or eliminated entirely by regularization, suggesting it is less important or possibly irrelevant.\n",
        "\t•\tConvergence at 10,000 (or any large value): Indicates the feature is highly influential, and its coefficient remains large because it plays a critical role in the model.\n",
        "\n",
        "Example: Lasso Regularization Path\n",
        "\n",
        "For Lasso regression, here’s what a regularization path might look like:\n",
        "\n",
        "\t•\tLow Regularization Strength: At the start (low regularization), all coefficients are non-zero and large.\n",
        "\t•\tIncreasing Regularization: As regularization increases, some coefficients begin to shrink toward zero.\n",
        "\t•\tHigh Regularization Strength: At high regularization values, many coefficients converge to zero, and only a few influential features retain non-zero coefficients.\n",
        "\n",
        "Summary:\n",
        "\n",
        "\t•\tConvergence to zero means regularization is shrinking the coefficients of less important features, reducing model complexity, and helping with feature selection (especially in Lasso and Elastic Net).\n",
        "\t•\tConvergence to a large value (like 10,000) indicates that certain features remain important to the model despite the application of regularization. This typically means these features have a strong predictive power.\n",
        "\t•\tThe goal of regularization is to find a balance, ensuring that the model generalizes well without overfitting or underfitting the data."
      ],
      "metadata": {
        "id": "AzsRu4virLQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw47dzwxDg2l"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Perform Ridge regression with Standard Scaler and alpha=0.5\n",
        "ridge_model = make_pipeline(StandardScaler(), Ridge(alpha=0.5))\n",
        "ridge_model.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "\n",
        "# Calculate cross-validation scores\n",
        "cv_scores = cross_val_score(ridge_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Calculate validation errors for Ridge regression model\n",
        "ME_ridge = np.mean(y_pred_ridge - y_test)\n",
        "RMSE_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "MAE_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "MPE_ridge = np.mean((y_pred_ridge - y_test) / y_test) * 100\n",
        "MAPE_ridge = np.mean(np.abs((y_pred_ridge - y_test) / y_test)) * 100\n",
        "\n",
        "# Get coefficients and corresponding variable names\n",
        "coefficients = ridge_model.named_steps['ridge'].coef_\n",
        "initial_variables = X_train.columns.tolist()\n",
        "\n",
        "# Set a threshold to consider coefficients as dropped\n",
        "threshold = 1e-5\n",
        "retained_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) > threshold]\n",
        "dropped_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) <= threshold]\n",
        "\n",
        "# Calculate VIF for each feature in the retained variables\n",
        "X_train_retained = X_train[retained_variables]\n",
        "X_train_const = sm.add_constant(X_train_retained)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Fit a linear model using statsmodels to get p-values, AIC, and BIC\n",
        "linear_model_sm = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = linear_model_sm.pvalues\n",
        "r_squared = linear_model_sm.rsquared\n",
        "adj_r_squared = linear_model_sm.rsquared_adj\n",
        "f_statistic = linear_model_sm.fvalue\n",
        "aic = linear_model_sm.aic\n",
        "bic = linear_model_sm.bic\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_full = [ridge_model.named_steps['ridge'].intercept_] + coefficients.tolist()\n",
        "p_values_full = [None] + p_values.tolist()  # Add None for the intercept\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': ['Intercept'] + retained_variables,\n",
        "    'Coefficient': coefficients_full[:len(retained_variables) + 1],\n",
        "    'P-Value': p_values_full[:len(retained_variables) + 1],\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print(\"\\nCross-Validation MSE:\", cv_mse)\n",
        "print(\"\\nValidation Errors:\")\n",
        "print(\"Mean Error (ME):\", ME_ridge)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE_ridge)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE_ridge)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE_ridge)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE_ridge)\n",
        "print(\"\\nModel Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "ridge_ME = ME_ridge\n",
        "ridge_RMSE = RMSE_ridge\n",
        "ridge_MAE = MAE_ridge\n",
        "ridge_MPE = MPE_ridge\n",
        "ridge_MAPE = MAPE_ridge\n",
        "ridge_r_squared = r_squared\n",
        "ridge_adjusted_r_squared = adj_r_squared\n",
        "ridge_f_statistic = f_statistic\n",
        "ridge_aic = aic\n",
        "ridge_bic = bic\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred_ridge\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_ridge, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Regularization Path\n",
        "alphas = np.logspace(-6, 6, 200)\n",
        "coefs = []\n",
        "for a in alphas:\n",
        "    ridge = Ridge(alpha=a)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    coefs.append(ridge.coef_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alphas, coefs)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficients')\n",
        "plt.title('Ridge Regression Regularization Path')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_ridge, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Ridge Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso regression (Least Absolute Shrinkage and Selection Operator) is a type of linear regression that adds an L1 regularization term to the cost function. This regularization penalizes the absolute values of the regression coefficients, forcing some of them to become exactly zero. As a result, lasso performs both feature selection and regularization, effectively simplifying the model by reducing the number of predictors. It is particularly useful when you have a large number of features, as it helps identify the most important ones while preventing overfitting."
      ],
      "metadata": {
        "id": "A_7hshQl5Lrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation is a statistical technique used to evaluate and improve the performance of a model by assessing how well it generalizes to unseen data. In the context of regression analysis, cross-validation is used to estimate the model’s performance on data that was not used to fit the model, helping to avoid overfitting.\n",
        "\n",
        "Key Concepts:\n",
        "\n",
        "\t1.\tOverfitting:\n",
        "\t•\tOverfitting occurs when a model learns not only the underlying patterns in the training data but also the noise or random fluctuations. This leads to poor performance on unseen data.\n",
        "\t•\tCross-validation helps to avoid overfitting by testing the model on different subsets of the data, ensuring that it generalizes well.\n",
        "\t2.\tTrain-Test Split:\n",
        "\t•\tIn a basic model evaluation, you typically split the dataset into two parts: training data and testing data. The model is trained on the training data and evaluated on the testing data.\n",
        "\t•\tHowever, this simple split can lead to issues because the model performance can be highly dependent on how the data was split.\n",
        "\t3.\tK-Fold Cross-Validation:\n",
        "\t•\tK-fold cross-validation is the most common form of cross-validation.\n",
        "\t•\tThe data is randomly split into K equal-sized subsets (folds).\n",
        "\t•\tThe model is trained on K-1 folds and tested on the remaining fold. This process is repeated K times, with each fold being used once as the testing set.\n",
        "\t•\tThe average performance across all K folds is then used as the final performance estimate of the model.\n",
        "Example of 5-Fold Cross-Validation:\n",
        "\t•\tSplit the data into 5 parts (folds).\n",
        "\t•\tTrain the model on 4 parts and test it on the 5th part. Repeat this process 5 times (each time, a different part is used for testing).\n",
        "  \t4.\tLeave-One-Out Cross-Validation (LOOCV):\n",
        "\t•\tA special case of cross-validation where the number of folds is equal to the number of data points. Each time, the model is trained on all but one data point and tested on the left-out data point. This process is repeated for all data points.\n",
        "\t5.\tStratified Cross-Validation:\n",
        "\t•\tIn cases where the data has certain characteristics, such as imbalanced classes, stratified cross-validation ensures that each fold has approximately the same distribution of target variable values as the full dataset.\n",
        "\n",
        "Steps in Cross-Validation for Regression:\n",
        "\n",
        "\t1.\tDivide the data into K folds.\n",
        "\t2.\tFor each fold:\n",
        "\t•\tTrain the model on K-1 folds.\n",
        "\t•\tTest the model on the remaining fold.\n",
        "\t3.\tCalculate the performance metrics (e.g., mean squared error or R-squared) for each fold.\n",
        "\t4.\tAverage the performance metrics across all folds to get a final estimate of the model’s performance.\n",
        "\n",
        "Why Use Cross-Validation in Regression?\n",
        "\n",
        "\t1.\tAvoid Overfitting:\n",
        "\t•\tCross-validation helps ensure that your regression model is not just memorizing the training data but also generalizing well to new, unseen data.\n",
        "\t2.\tBetter Performance Estimates:\n",
        "\t•\tA single train-test split might give a misleading performance estimate. Cross-validation provides a more reliable and stable estimate of model performance by evaluating the model on multiple subsets of data.\n",
        "\t3.\tHyperparameter Tuning:\n",
        "\t•\tCross-validation is often used in combination with hyperparameter tuning (e.g., choosing the best regularization parameter in Ridge or Lasso regression) to select the optimal model configuration."
      ],
      "metadata": {
        "id": "Nr6nIYnnpDua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHE4BF-QDg2l"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Perform Lasso regression with Standard Scaler and alpha=0.5\n",
        "lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=1))\n",
        "lasso_model.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso_model.predict(X_test)\n",
        "\n",
        "# Calculate cross-validation scores\n",
        "cv_scores = cross_val_score(lasso_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Calculate validation errors for Lasso regression model\n",
        "ME_lasso = np.mean(y_pred_lasso - y_test)\n",
        "RMSE_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
        "MAE_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "MPE_lasso = np.mean((y_pred_lasso - y_test) / y_test) * 100\n",
        "MAPE_lasso = np.mean(np.abs((y_pred_lasso - y_test) / y_test)) * 100\n",
        "\n",
        "# Get coefficients and corresponding variable names\n",
        "coefficients = lasso_model.named_steps['lasso'].coef_\n",
        "initial_variables = X_train.columns.tolist()\n",
        "\n",
        "# Retained and dropped variables\n",
        "retained_variables = [var for var, coef in zip(initial_variables, coefficients) if coef != 0]\n",
        "dropped_variables = [var for var, coef in zip(initial_variables, coefficients) if coef == 0]\n",
        "\n",
        "# Calculate VIF for each feature in the retained variables\n",
        "X_train_retained = X_train[retained_variables]\n",
        "X_train_const = sm.add_constant(X_train_retained)\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# Fit a linear model using statsmodels to get p-values, R-squared, adjusted R-squared, AIC, BIC, and F-statistic\n",
        "linear_model_sm = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = linear_model_sm.pvalues\n",
        "r_squared = linear_model_sm.rsquared\n",
        "adj_r_squared = linear_model_sm.rsquared_adj\n",
        "f_statistic = linear_model_sm.fvalue\n",
        "aic = linear_model_sm.aic\n",
        "bic = linear_model_sm.bic\n",
        "\n",
        "# Create a DataFrame to display variable names, coefficients, p-values, and VIF\n",
        "coefficients_full = [lasso_model.named_steps['lasso'].intercept_] + coefficients.tolist()\n",
        "p_values_full = [None] + p_values.tolist()  # Add None for the intercept\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': ['Intercept'] + retained_variables,\n",
        "    'Coefficient': coefficients_full[:len(retained_variables) + 1],\n",
        "    'P-Value': p_values_full[:len(retained_variables) + 1],\n",
        "    'VIF': vif_data[\"VIF\"]\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print(\"\\nCross-Validation MSE:\", cv_mse)\n",
        "print(\"\\nValidation Errors:\")\n",
        "print(\"Mean Error (ME):\", ME_lasso)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE_lasso)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE_lasso)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE_lasso)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE_lasso)\n",
        "print(\"\\nModel Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "lasso_ME = ME_lasso\n",
        "lasso_RMSE = RMSE_lasso\n",
        "lasso_MAE = MAE_lasso\n",
        "lasso_MPE = MPE_lasso\n",
        "lasso_MAPE = MAPE_lasso\n",
        "lasso_r_squared = r_squared\n",
        "lasso_adjusted_r_squared = adj_r_squared\n",
        "lasso_f_statistic = f_statistic\n",
        "lasso_aic = aic\n",
        "lasso_bic = bic\n",
        "\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred_lasso\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_lasso, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Regularization Path\n",
        "alphas = np.logspace(-6, 6, 200)\n",
        "coefs = []\n",
        "for a in alphas:\n",
        "    lasso = Lasso(alpha=a)\n",
        "    lasso.fit(X_train, y_train)\n",
        "    coefs.append(lasso.coef_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alphas, coefs)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficients')\n",
        "plt.title('Lasso Regression Regularization Path')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_lasso, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Lasso Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Q8m_PYDg2m"
      },
      "source": [
        "**Create and Elastic Net Model fitted with alpha=0.5 and l1_ratio=0.5**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lastic Net is a type of linear regression that combines both L1 (Lasso) and L2 (Ridge) regularization. It adds a penalty to the model's coefficients, balancing between feature selection (Lasso's strength) and coefficient shrinkage (Ridge's strength). This makes Elastic Net particularly useful when dealing with datasets that have many correlated predictors or when you want to benefit from both feature selection and regularization.\n",
        "\n",
        "Key Parameters:\n",
        "Alpha (α): Controls the overall strength of the regularization. A higher α increases the regularization effect, making the coefficients smaller and reducing overfitting.\n",
        "L1 Ratio (ratio): Determines the balance between Lasso and Ridge regularization:\n",
        "ratio = 1: Pure Lasso regularization (only L1 penalty).\n",
        "ratio = 0: Pure Ridge regularization (only L2 penalty).\n",
        "0 < ratio < 1: A combination of both Lasso and Ridge penalties.\n",
        "Elastic Net is a flexible method that helps in scenarios where neither Lasso nor Ridge alone works perfectly, such as when you have multicollinearity or sparse data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ehLC8YBv5qO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBbeLAtFDg2m"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df_cleaned_columns.drop(columns=['Ug_enter'])\n",
        "y = df_cleaned_columns['Ug_enter']\n",
        "\n",
        "# Split the dataset into training (60%) and test sets (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
        "\n",
        "# Perform Elastic Net regression with Standard Scaler, alpha=0.5, and l1_ratio=0.5\n",
        "elastic_net_model = make_pipeline(StandardScaler(), ElasticNet(alpha=0.5, l1_ratio=0.5))\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "y_pred_en = elastic_net_model.predict(X_test)\n",
        "\n",
        "# Calculate cross-validation scores\n",
        "cv_scores = cross_val_score(elastic_net_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Calculate validation errors for Elastic Net regression model\n",
        "ME_en = np.mean(y_pred_en - y_test)\n",
        "RMSE_en = np.sqrt(mean_squared_error(y_test, y_pred_en))\n",
        "MAE_en = mean_absolute_error(y_test, y_pred_en)\n",
        "MPE_en = np.mean((y_pred_en - y_test) / y_test) * 100\n",
        "MAPE_en = np.mean(np.abs((y_pred_en - y_test) / y_test)) * 100\n",
        "\n",
        "# Get coefficients and corresponding variable names\n",
        "coefficients = elastic_net_model.named_steps['elasticnet'].coef_\n",
        "initial_variables = X_train.columns.tolist()\n",
        "\n",
        "# Retained and dropped variables based on Elastic Net coefficients\n",
        "retained_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) > 1e-5]\n",
        "dropped_variables = [var for var, coef in zip(initial_variables, coefficients) if abs(coef) <= 1e-5]\n",
        "\n",
        "# Calculate VIF for each feature in the retained variables\n",
        "def calculate_vif(X):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"Variable\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif\n",
        "\n",
        "X_train_retained = X_train[retained_variables]\n",
        "vif_data = calculate_vif(X_train_retained)\n",
        "\n",
        "while vif_data['VIF'].max() > 10:\n",
        "    var_to_drop = vif_data.loc[vif_data['VIF'].idxmax(), 'Variable']\n",
        "    retained_variables.remove(var_to_drop)\n",
        "    dropped_variables.append(var_to_drop)\n",
        "    X_train_retained = X_train[retained_variables]\n",
        "    vif_data = calculate_vif(X_train_retained)\n",
        "\n",
        "# Fit a linear model using statsmodels to get p-values, R-squared, adjusted R-squared, AIC, BIC, and F-statistic\n",
        "X_train_const = sm.add_constant(X_train_retained)\n",
        "linear_model_sm = sm.OLS(y_train, X_train_const).fit()\n",
        "p_values = linear_model_sm.pvalues\n",
        "r_squared = linear_model_sm.rsquared\n",
        "adj_r_squared = linear_model_sm.rsquared_adj\n",
        "f_statistic = linear_model_sm.fvalue\n",
        "aic = linear_model_sm.aic\n",
        "bic = linear_model_sm.bic\n",
        "\n",
        "# Ensure that lengths are aligned before creating the DataFrame\n",
        "coefficients_full = [linear_model_sm.params[0]] + linear_model_sm.params[1:].tolist()\n",
        "p_values_full = [None] + p_values[1:].tolist()  # Add None for the intercept\n",
        "vif_full = [None] + vif_data[\"VIF\"].tolist()\n",
        "\n",
        "assert len(coefficients_full) == len(p_values_full) == len(vif_full) == len(['Intercept'] + retained_variables), \"Array lengths do not match.\"\n",
        "\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Variable': ['Intercept'] + retained_variables,\n",
        "    'Coefficient': coefficients_full,\n",
        "    'P-Value': p_values_full,\n",
        "    'VIF': vif_full\n",
        "})\n",
        "\n",
        "# Print results\n",
        "print(\"Dropped Variables:\")\n",
        "for variable in dropped_variables:\n",
        "    print(variable)\n",
        "print(\"Coefficients, P-Values, and VIF:\")\n",
        "print(coefficients_df)\n",
        "print()\n",
        "print(\"Cross-Validation MSE:\", cv_mse)\n",
        "print()\n",
        "print(\"Validation Errors:\")\n",
        "print(\"Mean Error (ME):\", ME_en)\n",
        "print(\"Root Mean Square Error (RMSE):\", RMSE_en)\n",
        "print(\"Mean Absolute Error (MAE):\", MAE_en)\n",
        "print(\"Mean Percentage Error (MPE):\", MPE_en)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", MAPE_en)\n",
        "print()\n",
        "print(\"Model Statistics:\")\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "print(\"F-statistic:\", f_statistic)\n",
        "print(\"AIC:\", aic)\n",
        "print(\"BIC:\", bic)\n",
        "\n",
        "elastic_net_ME = ME_en\n",
        "elastic_net_RMSE = RMSE_en\n",
        "elastic_net_MAE = MAE_en\n",
        "elastic_net_MPE = MPE_en\n",
        "elastic_net_MAPE = MAPE_en\n",
        "elastic_net_r_squared = r_squared\n",
        "elastic_net_adjusted_r_squared = adj_r_squared\n",
        "elastic_net_f_statistic = f_statistic\n",
        "elastic_net_aic = aic\n",
        "elastic_net_bic = bic\n",
        "\n",
        "\n",
        "# Residual Analysis\n",
        "residuals = y_test - y_pred_en\n",
        "\n",
        "# Plot the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_en, residuals, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot for residuals\n",
        "sm.qqplot(residuals, line='45')\n",
        "plt.title('Q-Q Plot')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Histogram of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Regularization Path\n",
        "alphas = np.logspace(-6, 6, 200)\n",
        "coefs = []\n",
        "for a in alphas:\n",
        "    elastic_net = ElasticNet(alpha=a, l1_ratio=0.5)\n",
        "    elastic_net.fit(X_train, y_train)\n",
        "    coefs.append(elastic_net.coef_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for coef in np.array(coefs).T:\n",
        "    plt.plot(alphas, coef)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficients')\n",
        "plt.title('Elastic Net Regression Regularization Path')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_en, color='blue', edgecolor='k', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Elastic Net Regression: Actual vs Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyhOXBXWDg2m"
      },
      "source": [
        "**Comparison of the Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBzpiwuxDg2m"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    'Model': ['Linear', 'Forward Selection', 'Backward Elimination', 'Ridge', 'Lasso', 'Elastic Net'],\n",
        "    'RMSE': [liner_RMSE, forward_RMSE, backward_RMSE, RMSE_ridge, RMSE_lasso, RMSE_en],\n",
        "    'MAE': [linear_MAE, forward_MAE, backward_MAE, MAE_ridge, MAE_lasso, MAE_en],\n",
        "    'R-squared': [linear_r_squared, forward_r_squared, backward_r_squared, ridge_r_squared, lasso_r_squared, elastic_net_r_squared],\n",
        "    'Adjusted R-squared': [linear_adjusted_r_squared, forward_adjusted_r_squared, backward_adjusted_r_squared, ridge_adjusted_r_squared, lasso_adjusted_r_squared, elastic_net_adjusted_r_squared],\n",
        "    'AIC': [linear_aic, forward_aic, backward_aic, ridge_aic, lasso_aic, elastic_net_aic],\n",
        "    'BIC': [linear_bic, forward_bic, backward_bic, ridge_bic, lasso_bic, elastic_net_bic]\n",
        "}\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Adjust display settings to avoid wrapping columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"Comparison of Regression Models:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFnUBVDzDg2m"
      },
      "source": [
        "**Best Fit Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lwDrS0gDg2m"
      },
      "outputs": [],
      "source": [
        "# Function to determine the best model based on given criteria\n",
        "def find_best_model(results_df):\n",
        "    # Rank models based on each metric\n",
        "    results_df['RMSE_rank'] = results_df['RMSE'].rank(ascending=True)\n",
        "    results_df['MAE_rank'] = results_df['MAE'].rank(ascending=True)\n",
        "    results_df['R-squared_rank'] = results_df['R-squared'].rank(ascending=False)\n",
        "    results_df['Adjusted_R-squared_rank'] = results_df['Adjusted R-squared'].rank(ascending=False)\n",
        "    results_df['AIC_rank'] = results_df['AIC'].rank(ascending=True)\n",
        "    results_df['BIC_rank'] = results_df['BIC'].rank(ascending=True)\n",
        "\n",
        "    # Calculate total rank (lower is better)\n",
        "    results_df['Total_rank'] = results_df[['RMSE_rank', 'MAE_rank', 'R-squared_rank', 'Adjusted_R-squared_rank', 'AIC_rank', 'BIC_rank']].sum(axis=1)\n",
        "\n",
        "    # Find the best model\n",
        "    best_model = results_df.loc[results_df['Total_rank'].idxmin()]\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Find the best model\n",
        "best_model = find_best_model(results_df)\n",
        "\n",
        "print(\"Best Model:\")\n",
        "print(best_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}