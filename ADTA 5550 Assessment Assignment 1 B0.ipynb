{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Answer the following questions. Keep your answers short. You can use any resource to answer the questions although the slides are sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What are CPU, GPU, and TPU? Which of these does PyTorch prefer to perform better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is Colab, where is it and why do NOT you need to install PyTorch and TensorFlow to Colab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How do you use GPU runtime with Colab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Introduce the MNIST data set shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What do we mean by \"learning\" in ML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Which three layers does a typical neural network include?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Which activation function is the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A7. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What is backpropagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A8. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. What is the Loss Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A9. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. What is a tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A10. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. Why do we use PyTorch instead of other PyThon libraries of ML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Python code blocks to practice. Run the following code blocks following the instructions.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "Put a comment at the beginning of each code block to explain it with your initials and last two digits of your ID number. I have put one at the beginning as an example for you to follow. Do not forget to change it. Name all variables similarly: for instance, x = 3 below will be modified as xJD54 = 3.\n",
    "\n",
    "Be sure to run all code blocks before you submit.\n",
    "\n",
    "(Important, Academic Integrity) Do not pass your code blocks to anyone. If one student's initials and digits appear in another's submission, both students will be degraded one letter and filed to the Academic Integrity Office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MO54\n",
    "# This code block imports the necessary libraries of Pyhton to be used in this session\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:32:54.676062Z",
     "start_time": "2021-03-22T05:32:54.671481Z"
    }
   },
   "outputs": [],
   "source": [
    "torch_scalar = torch.tensor(3.14)\n",
    "torch_vector = torch.tensor([1, 2, 3, 4])\n",
    "torch_matrix = torch.tensor([[1, 2,],\n",
    "                             [3, 4,],\n",
    "                             [5, 6,], \n",
    "                             [7, 8,]])\n",
    "#You don't have to format it like I did, thats just for clarity\n",
    "torch_tensor3d = torch.tensor([\n",
    "                            [\n",
    "                            [ 1,  2,  3], \n",
    "                            [ 4,  5,  6],\n",
    "                            ],\n",
    "                            [\n",
    "                            [ 7,  8,  9], \n",
    "                            [10, 11, 12],\n",
    "                            ],\n",
    "                            [\n",
    "                            [13, 14, 15], \n",
    "                            [16, 17, 18],\n",
    "                            ],\n",
    "                            [\n",
    "                            [19, 20, 21], \n",
    "                            [22, 23, 24],\n",
    "                            ]\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Define three PyTorch scalars, vectors, matrices and 3d tensors** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_scalar.shape)\n",
    "print(torch_vector.shape)\n",
    "print(torch_matrix.shape)\n",
    "print(torch_tensor3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Print the shapes of your scalars, vectors, matrices and 3d tensors** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.random.random((4,4))\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pt = torch.tensor(x_np)\n",
    "print(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_np.dtype, x_pt.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.asarray(x_np, dtype=np.float32)\n",
    "x_pt = torch.tensor(x_np, dtype=torch.float32)\n",
    "print(x_np.dtype, x_pt.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_np = (x_np > 0.5)\n",
    "print(b_np)\n",
    "print(b_np.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pt = (x_pt > 0.5)\n",
    "print(b_pt)\n",
    "print(b_pt.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(x_pt, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.transpose(torch_tensor3d, 0, 2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:32:59.532902Z",
     "start_time": "2021-03-22T05:32:54.765163Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "x = torch.rand(2**11, 2**11)\n",
    "time_cpu = timeit.timeit(\"x@x\", globals=globals(), number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is CUDA available? :\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:33:01.740576Z",
     "start_time": "2021-03-22T05:32:59.580308Z"
    }
   },
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "time_gpu = timeit.timeit(\"x@x\", globals=globals(), number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveTo(obj, device):\n",
    "    \"\"\"\n",
    "    obj: the python object to move to a device, or to move its contents to a device\n",
    "    device: the compute device to move objects to\n",
    "    \"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return [moveTo(x, device) for x in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(moveTo(list(obj), device))\n",
    "    elif isinstance(obj, set):\n",
    "        return set(moveTo(list(obj), device))\n",
    "    elif isinstance(obj, dict):\n",
    "        to_ret = dict()\n",
    "        for key, value in obj.items():\n",
    "            to_ret[moveTo(key, device)] = moveTo(value, device)\n",
    "        return to_ret\n",
    "    elif hasattr(obj, \"to\"):\n",
    "        return obj.to(device)\n",
    "    else:\n",
    "        return obj\n",
    "    \n",
    "some_tensors = [torch.tensor(1), torch.tensor(2)]\n",
    "print(some_tensors)\n",
    "print(moveTo(some_tensors, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Repeat the following figure with the cube of (x-10)** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.pow((x-2.0), 2)\n",
    "\n",
    "x_axis_vals = np.linspace(-7,9,100) \n",
    "y_axis_vals = f(torch.tensor(x_axis_vals)).numpy()\n",
    "\n",
    "sns.lineplot(x=x_axis_vals, y=y_axis_vals, label='$f(x)=(x-2)^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fP(x): #Defining the derivative of f(x) manually\n",
    "    return 2*x-4\n",
    "\n",
    "y_axis_vals_p = fP(torch.tensor(x_axis_vals)).numpy()\n",
    "\n",
    "#First, lets draw a black line at 0, so that we can easily tell if something is positive or negative\n",
    "sns.lineplot(x=x_axis_vals, y=[0.0]*len(x_axis_vals), label=\"0\", color='black')\n",
    "sns.lineplot(x=x_axis_vals, y=y_axis_vals, label='$f(x) = (x-2)^2$')\n",
    "sns.lineplot(x=x_axis_vals, y=y_axis_vals_p, label=\"$f'(x)=2 x - 4$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-3.5], requires_grad=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = f(x)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-3.5], requires_grad=True)\n",
    "\n",
    "x_cur = x.clone()\n",
    "x_prev = x_cur*100 #Make the initial \"previous\" solution larger\n",
    "epsilon = 1e-5\n",
    "eta = 0.1\n",
    "\n",
    "while torch.linalg.norm(x_cur-x_prev) > epsilon:\n",
    "    x_prev = x_cur.clone() #We need to make a clone here so that x_prev and x_cur don't point to the same object\n",
    "    \n",
    "    #Compute our function, gradient, and update\n",
    "    value = f(x)\n",
    "    value.backward()\n",
    "    x.data -= eta * x.grad\n",
    "    x.grad.zero_() #We need to zero out the old gradient, as py-torch will not do that for us\n",
    "    \n",
    "    #What are we currently now?\n",
    "    x_cur = x.data\n",
    "    \n",
    "print(x_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:33:02.911171Z",
     "start_time": "2021-03-22T05:33:02.908110Z"
    }
   },
   "outputs": [],
   "source": [
    "x_param = torch.nn.Parameter(torch.tensor([-3.5]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:33:02.916541Z",
     "start_time": "2021-03-22T05:33:02.913522Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([x_param], lr=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(60):\n",
    "    optimizer.zero_grad() #x.grad.zero_()\n",
    "    loss_incurred  = f(x_param)\n",
    "    loss_incurred.backward()\n",
    "    optimizer.step() #x.data -= eta * x.grad\n",
    "print(x_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T05:33:18.684096Z",
     "start_time": "2021-03-22T05:33:18.680539Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        super(SimpleDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #This \"work\" could have gone in the constructor, but you should get into \n",
    "        inputs = torch.tensor(self.X.iloc[index, :].values, dtype=torch.float32)\n",
    "        targets = torch.tensor(int(self.y[index]), dtype=torch.int64)\n",
    "        return inputs, targets \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "#Now we can make a PyTorch dataset \n",
    "dataset = SimpleDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length: \", len(dataset))\n",
    "example, label = dataset[0]\n",
    "print(\"Features: \", example.shape) #Will return 784\n",
    "print(\"Label of index 0: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Print the folowing shapes with four different such numbers from the same data set** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset)*0.8)\n",
    "test_size = len(dataset)-train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, (train_size, test_size))\n",
    "print(\"{} examples for training and {} for testing\".format(len(train_dataset), len(test_dataset)))"
   ]
  }
 ],
 "metadata": {
  "author": "Why PyTorch?",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "latex_metadata": {
   "title": "The Mechanics of Learning"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
